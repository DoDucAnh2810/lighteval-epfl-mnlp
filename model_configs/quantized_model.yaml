model:
  base_params:
    model_args: "pretrained=HuggingFaceH4/zephyr-7b-beta,revision=main" # Change this to your own model name on huggingface hub
    dtype: "4bit"  # Specifying the model to be loaded in 4 bit uses BitsAndBytesConfig. The other option is to use "8bit" quantization.
    compile: false
  merged_weights: # Ignore this section if you are not using PEFT models
    delta_weights: false # set to True of your model should be merged with a base model, also need to provide the base model name
    adapter_weights: false # set to True of your model has been trained with peft, also need to provide the base model name
    base_model: null # path to the base_model - needs to be specified only if delta_weights or adapter_weights is set to True
  generation:
    temperature: 0.0
