model:
  base_params:
    model_args: "pretrained=HuggingFaceH4/zephyr-7b-beta,revision=main" # Change this to your own model name on huggingface hub
    dtype: "4bit"  # Specifying the model to be loaded in 4 bit. The other option is to use "8bit" quantization.
    compile: false

  # Ignore this section, do not modify!
  merged_weights:
    delta_weights: false
    adapter_weights: false
    base_model: null
  generation:
    temperature: 0.0
